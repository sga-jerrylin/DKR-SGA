"""
OCR ç¼“å­˜æ¨¡å—

ç¼“å­˜å·² OCR çš„é¡µé¢ï¼Œé¿å…é‡å¤å¤„ç†
"""

import json
import hashlib
from pathlib import Path
from typing import Optional, Dict
import logging

logger = logging.getLogger(__name__)


class OCRCache:
    """
    OCR ç»“æœç¼“å­˜
    
    ç¼“å­˜ç­–ç•¥ï¼š
    - é”®: video_path + frame_num çš„å“ˆå¸Œ
    - å€¼: OCR ç»“æœï¼ˆJSONï¼‰
    - å­˜å‚¨: æœ¬åœ°æ–‡ä»¶ç³»ç»Ÿ
    """
    
    def __init__(self, cache_dir: str = "ocr_cache"):
        """
        åˆå§‹åŒ–ç¼“å­˜
        
        Args:
            cache_dir: ç¼“å­˜ç›®å½•
        """
        self.cache_dir = Path(cache_dir)
        self.cache_dir.mkdir(exist_ok=True, parents=True)
        
        logger.info(f"ğŸ“¦ OCR ç¼“å­˜ç›®å½•: {self.cache_dir}")
    
    def _get_cache_key(self, video_path: str, frame_num: int) -> str:
        """
        ç”Ÿæˆç¼“å­˜é”®
        
        Args:
            video_path: è§†é¢‘æ–‡ä»¶è·¯å¾„
            frame_num: å¸§å·
        
        Returns:
            ç¼“å­˜é”®ï¼ˆå“ˆå¸Œï¼‰
        """
        # ä½¿ç”¨è§†é¢‘è·¯å¾„ + å¸§å·ç”Ÿæˆå”¯ä¸€é”®
        key_str = f"{Path(video_path).resolve()}_{frame_num}"
        return hashlib.md5(key_str.encode()).hexdigest()
    
    def _get_cache_file(self, video_path: str, frame_num: int) -> Path:
        """
        è·å–ç¼“å­˜æ–‡ä»¶è·¯å¾„
        
        Args:
            video_path: è§†é¢‘æ–‡ä»¶è·¯å¾„
            frame_num: å¸§å·
        
        Returns:
            ç¼“å­˜æ–‡ä»¶è·¯å¾„
        """
        cache_key = self._get_cache_key(video_path, frame_num)
        
        # ä½¿ç”¨è§†é¢‘åç§°ä½œä¸ºå­ç›®å½•ï¼ˆä¾¿äºç®¡ç†ï¼‰
        video_name = Path(video_path).stem
        cache_subdir = self.cache_dir / video_name
        cache_subdir.mkdir(exist_ok=True)
        
        return cache_subdir / f"{cache_key}.json"
    
    def get(self, video_path: str, frame_num: int) -> Optional[str]:
        """
        è·å–ç¼“å­˜çš„ OCR ç»“æœ
        
        Args:
            video_path: è§†é¢‘æ–‡ä»¶è·¯å¾„
            frame_num: å¸§å·
        
        Returns:
            OCR ç»“æœï¼Œå¦‚æœä¸å­˜åœ¨åˆ™è¿”å› None
        """
        cache_file = self._get_cache_file(video_path, frame_num)
        
        if not cache_file.exists():
            return None
        
        try:
            with cache_file.open('r', encoding='utf-8') as f:
                data = json.load(f)
                logger.debug(f"âœ… ç¼“å­˜å‘½ä¸­: ç¬¬ {frame_num + 1} é¡µ")
                return data.get('content')
        except Exception as e:
            logger.warning(f"âš ï¸ ç¼“å­˜è¯»å–å¤±è´¥: {e}")
            return None
    
    def set(self, video_path: str, frame_num: int, content: str):
        """
        è®¾ç½®ç¼“å­˜
        
        Args:
            video_path: è§†é¢‘æ–‡ä»¶è·¯å¾„
            frame_num: å¸§å·
            content: OCR ç»“æœ
        """
        cache_file = self._get_cache_file(video_path, frame_num)
        
        try:
            with cache_file.open('w', encoding='utf-8') as f:
                json.dump({
                    'video_path': str(video_path),
                    'frame_num': frame_num,
                    'content': content
                }, f, ensure_ascii=False, indent=2)
            
            logger.debug(f"ğŸ’¾ ç¼“å­˜å·²ä¿å­˜: ç¬¬ {frame_num + 1} é¡µ")
        except Exception as e:
            logger.warning(f"âš ï¸ ç¼“å­˜ä¿å­˜å¤±è´¥: {e}")
    
    def clear(self, video_path: Optional[str] = None):
        """
        æ¸…é™¤ç¼“å­˜
        
        Args:
            video_path: å¦‚æœæŒ‡å®šï¼Œåªæ¸…é™¤è¯¥è§†é¢‘çš„ç¼“å­˜ï¼›å¦åˆ™æ¸…é™¤æ‰€æœ‰ç¼“å­˜
        """
        if video_path:
            # æ¸…é™¤ç‰¹å®šè§†é¢‘çš„ç¼“å­˜
            video_name = Path(video_path).stem
            cache_subdir = self.cache_dir / video_name
            
            if cache_subdir.exists():
                import shutil
                shutil.rmtree(cache_subdir)
                logger.info(f"ğŸ—‘ï¸ å·²æ¸…é™¤ç¼“å­˜: {video_name}")
        else:
            # æ¸…é™¤æ‰€æœ‰ç¼“å­˜
            import shutil
            shutil.rmtree(self.cache_dir)
            self.cache_dir.mkdir(exist_ok=True)
            logger.info(f"ğŸ—‘ï¸ å·²æ¸…é™¤æ‰€æœ‰ç¼“å­˜")
    
    def get_stats(self, video_path: Optional[str] = None) -> Dict:
        """
        è·å–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯
        
        Args:
            video_path: å¦‚æœæŒ‡å®šï¼Œåªç»Ÿè®¡è¯¥è§†é¢‘çš„ç¼“å­˜
        
        Returns:
            ç»Ÿè®¡ä¿¡æ¯
        """
        if video_path:
            video_name = Path(video_path).stem
            cache_subdir = self.cache_dir / video_name
            
            if not cache_subdir.exists():
                return {
                    'video': video_name,
                    'cached_pages': 0,
                    'total_size': 0
                }
            
            cache_files = list(cache_subdir.glob('*.json'))
            total_size = sum(f.stat().st_size for f in cache_files)
            
            return {
                'video': video_name,
                'cached_pages': len(cache_files),
                'total_size': total_size,
                'avg_size': total_size / len(cache_files) if cache_files else 0
            }
        else:
            # ç»Ÿè®¡æ‰€æœ‰ç¼“å­˜
            all_cache_files = list(self.cache_dir.rglob('*.json'))
            total_size = sum(f.stat().st_size for f in all_cache_files)
            
            # æŒ‰è§†é¢‘åˆ†ç»„
            videos = {}
            for cache_file in all_cache_files:
                video_name = cache_file.parent.name
                if video_name not in videos:
                    videos[video_name] = 0
                videos[video_name] += 1
            
            return {
                'total_cached_pages': len(all_cache_files),
                'total_size': total_size,
                'videos': videos
            }

