"""
DKR Agent - åŸºäº LangGraph çš„è‡ªä¸» Agent å®ç°
"""
from typing import Dict, Any, Optional
from datetime import datetime
from loguru import logger

from langgraph.prebuilt import create_react_agent
from langgraph.checkpoint.memory import MemorySaver
from langchain_openai import ChatOpenAI
from langchain_core.tools import tool
from langchain_core.messages import HumanMessage

from app.core.library_manager import LibraryManager
from app.core.llm_client import DeepSeekLLMClient
from app.config import get_settings


# å…¨å±€å®ä¾‹ï¼ˆç”¨äºå·¥å…·å‡½æ•°è®¿é—®ï¼‰
_library_manager: Optional[LibraryManager] = None
_llm_client: Optional[DeepSeekLLMClient] = None


def _init_globals():
    """åˆå§‹åŒ–å…¨å±€å®ä¾‹"""
    global _library_manager, _llm_client
    if _library_manager is None:
        _library_manager = LibraryManager()
    if _llm_client is None:
        _llm_client = DeepSeekLLMClient()


# LangGraph å·¥å…·å®šä¹‰
@tool
def search_library_overview(query: str = "") -> str:
    """
    è·å–æ–‡æ¡£åº“æ¦‚è§ˆï¼ˆå›¾ä¹¦ç®¡ç†å‘˜è§†è§’ï¼‰ã€‚

    è¿™ä¸ªå·¥å…·ä¼šè¿”å›æ–‡æ¡£åº“çš„åˆ†ç±»åˆ—è¡¨ï¼Œæ¯ä¸ªåˆ†ç±»ä¸‹æœ‰å¤šå°‘ä»½æ–‡æ¡£ã€‚
    é€‚ç”¨äºï¼šä¸ç¡®å®šè¦åœ¨å“ªä¸ªåˆ†ç±»ä¸­æœç´¢æ—¶ä½¿ç”¨ã€‚

    Args:
        query: ç”¨æˆ·çš„æŸ¥è¯¢é—®é¢˜ï¼ˆå¯é€‰ï¼Œç”¨äºæ—¥å¿—è®°å½•ï¼‰

    Returns:
        æ–‡æ¡£åº“çš„åˆ†ç±»æ¦‚è§ˆä¿¡æ¯
    """
    _init_globals()
    logger.info(f"[Tool] search_library_overview: {query}")

    # è·å–åˆ†ç±»æ‘˜è¦
    summary = _library_manager.get_category_summary()

    return summary


@tool
def search_in_category(category: str, query: str = "") -> str:
    """
    æŸ¥çœ‹ç‰¹å®šåˆ†ç±»ä¸­çš„æ‰€æœ‰æ–‡æ¡£åˆ—è¡¨ï¼ˆå›¾ä¹¦ç®¡ç†å‘˜è§†è§’ï¼‰ã€‚

    è¿™ä¸ªå·¥å…·ä¼šè¿”å›è¯¥åˆ†ç±»ä¸‹æ‰€æœ‰æ–‡æ¡£çš„å…ƒä¿¡æ¯ï¼ŒåŒ…æ‹¬ï¼š
    - æ–‡ä»¶å
    - é¡µæ•°
    - æ–‡æ¡£æ‘˜è¦ï¼ˆå¤§æ¦‚å†…å®¹ï¼‰

    é€‚ç”¨äºï¼šå·²çŸ¥è¦åœ¨å“ªä¸ªåˆ†ç±»ä¸­æŸ¥æ‰¾ï¼Œéœ€è¦äº†è§£è¯¥åˆ†ç±»ä¸‹æœ‰å“ªäº›æ–‡æ¡£æ—¶ä½¿ç”¨ã€‚

    Args:
        category: åˆ†ç±»åç§°ï¼ˆå¦‚ï¼šè´¢åŠ¡ç±»ã€åˆ¶åº¦ç±»ã€ç®€å†ã€åˆåŒï¼‰
        query: ç”¨æˆ·çš„æŸ¥è¯¢é—®é¢˜ï¼ˆå¯é€‰ï¼Œç”¨äºæ—¥å¿—è®°å½•ï¼‰

    Returns:
        è¯¥åˆ†ç±»ä¸‹æ‰€æœ‰æ–‡æ¡£çš„è¯¦ç»†åˆ—è¡¨
    """
    _init_globals()
    logger.info(f"[Tool] search_in_category: category={category}, query={query}")

    documents = _library_manager.list_documents(category=category)

    if not documents:
        return f"åˆ†ç±» '{category}' ä¸­æ²¡æœ‰æ‰¾åˆ°æ–‡æ¡£"

    result = f"# åˆ†ç±» '{category}' ä¸­çš„æ–‡æ¡£åˆ—è¡¨\n\n"
    result += f"å…± {len(documents)} ä»½æ–‡æ¡£ï¼š\n\n"

    for i, doc in enumerate(documents, 1):
        metadata = doc.get('metadata', {})

        # æ–‡ä»¶å
        filename = metadata.get('filename', doc.get('title', doc['doc_id']))

        # é¡µæ•°
        page_count = metadata.get('page_count', 'æœªçŸ¥')

        # æ–‡æ¡£æ‘˜è¦
        doc_summary = metadata.get('doc_summary', 'æ— æ‘˜è¦')

        result += f"{i}. **{filename}**\n"
        result += f"   - æ–‡æ¡£ ID: {doc['doc_id']}\n"
        result += f"   - é¡µæ•°: {page_count} é¡µ\n"
        result += f"   - å†…å®¹æ‘˜è¦: {doc_summary}\n"
        result += f"\n"

    result += "\næç¤ºï¼šé€‰æ‹©ä¸€ä¸ªæ–‡æ¡£åï¼Œå¯ä»¥ä½¿ç”¨ search_in_document_summary æˆ– search_in_document è¿›è¡Œæ·±å…¥æ£€ç´¢ã€‚"

    return result


@tool
def search_in_document(doc_id: str, query: str, page_nums: list = None, top_k: int = 5) -> str:
    """
    ã€Stage 2 å·¥å…·ã€‘åœ¨ç‰¹å®šæ–‡æ¡£ä¸­æœç´¢ç­”æ¡ˆï¼ˆä½¿ç”¨ DeepSeek OCR å®æ—¶ç†è§£æ–‡æ¡£å†…å®¹ï¼‰ã€‚

    âš ï¸âš ï¸âš ï¸ ä¸¥é‡è­¦å‘Šï¼šè¿™æ˜¯æˆæœ¬æé«˜ã€é€Ÿåº¦ææ…¢çš„æ“ä½œï¼

    âš ï¸ ä½¿ç”¨å‰ææ¡ä»¶ï¼ˆå¿…é¡»æ»¡è¶³ï¼‰ï¼š
    1. å¿…é¡»å…ˆè°ƒç”¨ search_in_document_summary è·å– Summary
    2. å¿…é¡»å…ˆå°è¯•ç”¨ Summary å›ç­”é—®é¢˜
    3. å¿…é¡»ç¡®è®¤ Summary å®Œå…¨ä¸è¶³ä»¥å›ç­”é—®é¢˜
    4. å¿…é¡»è¯´æ˜ä¸ºä»€ä¹ˆ Summary ä¸è¶³ï¼ˆè®°å½•å†³ç­–ç†ç”±ï¼‰

    âš ï¸ å¦‚æœæœªæ»¡è¶³ä¸Šè¿°æ¡ä»¶ï¼Œç¦æ­¢è°ƒç”¨æ­¤å·¥å…·ï¼

    é€‚ç”¨åœºæ™¯ï¼ˆä»…é™ä»¥ä¸‹æƒ…å†µï¼‰ï¼š
    - Summary ä¿¡æ¯ä¸¥é‡ä¸è¶³ï¼Œæ— æ³•å›ç­”é—®é¢˜
    - éœ€è¦æŸ¥çœ‹å›¾è¡¨ã€è¡¨æ ¼çš„è¯¦ç»†å†…å®¹
    - éœ€è¦ç²¾ç¡®çš„æ•°å­—ã€å…¬å¼ã€ä»£ç ç­‰

    å·¥ä½œæµç¨‹ï¼š
    1. å¦‚æœæŒ‡å®šäº† page_numsï¼Œåª OCR è¿™äº›é¡µé¢ï¼ˆå¼ºçƒˆæ¨èï¼‰
    2. å¦‚æœæœªæŒ‡å®š page_numsï¼Œä½¿ç”¨è½»é‡çº§ç´¢å¼•å®šä½ top_k ä¸ªé¡µé¢
    3. è°ƒç”¨ DeepSeek OCR API å®æ—¶ç†è§£é¡µé¢å†…å®¹ï¼ˆè€—æ—¶ 3-5 ç§’/é¡µï¼‰
    4. è¿”å› OCR ç»“æœ

    Args:
        doc_id: æ–‡æ¡£ ID
        query: ç”¨æˆ·çš„æŸ¥è¯¢é—®é¢˜
        page_nums: æŒ‡å®šè¦ OCR çš„é¡µç åˆ—è¡¨ï¼ˆå¼ºçƒˆæ¨èï¼Œä¾‹å¦‚ [1, 3, 5]ï¼‰
        top_k: å¦‚æœæœªæŒ‡å®š page_numsï¼Œè¿”å›æœ€ç›¸å…³çš„é¡µé¢æ•°é‡ï¼ˆé»˜è®¤ 5ï¼Œæœ€å¤§ 5ï¼‰

    Returns:
        ä»æ–‡æ¡£ä¸­æ£€ç´¢åˆ°çš„ç­”æ¡ˆå’Œæ¥æºé¡µé¢
    """
    _init_globals()

    # å®‰å…¨æ£€æŸ¥
    if page_nums and len(page_nums) > 5:
        logger.warning(f"[Tool] âš ï¸ è¯·æ±‚ OCR {len(page_nums)} é¡µï¼Œè¶…è¿‡å»ºè®®çš„ 5 é¡µé™åˆ¶")
        return (
            f"âš ï¸ è­¦å‘Šï¼šæ‚¨è¯·æ±‚ OCR {len(page_nums)} é¡µï¼Œè¶…è¿‡å»ºè®®çš„ 5 é¡µé™åˆ¶ã€‚\n"
            f"å»ºè®®ï¼šè¯·ä»ä¸­é€‰æ‹© 3-5 é¡µæœ€ç›¸å…³çš„é¡µé¢ã€‚\n"
            f"åŸå› ï¼šå…¨é‡ OCR æˆæœ¬é«˜ã€é€Ÿåº¦æ…¢ï¼Œåº”ç²¾å‡†é€‰æ‹©é¡µé¢ã€‚"
        )

    if top_k > 5:
        logger.warning(f"[Tool] âš ï¸ top_k={top_k} è¶…è¿‡é™åˆ¶ï¼Œè‡ªåŠ¨è°ƒæ•´ä¸º 5")
        top_k = 5

    logger.info(f"[Tool] search_in_document: doc_id={doc_id}, query={query}, page_nums={page_nums}, top_k={top_k}")
    logger.info(f"[Tool] å°†è°ƒç”¨ DeepSeek OCR API è¿›è¡Œå®æ—¶æ–‡æ¡£ç†è§£")

    try:
        import sys
        from pathlib import Path

        # Add project root to path (to import visual_memvid)
        project_root = Path(__file__).parent.parent.parent.parent
        sys.path.insert(0, str(project_root))

        from visual_memvid.visual_retriever import VisualMemvidRetriever
        from visual_memvid.ocr_client import DeepSeekOCRClient
        from app.config import get_settings
        from app.core.library_manager import LibraryManager

        settings = get_settings()
        library_manager = LibraryManager()

        # è·å–æ–‡æ¡£ä¿¡æ¯
        doc_info = library_manager.get_document(doc_id)
        if not doc_info:
            return f"é”™è¯¯ï¼šæ–‡æ¡£ {doc_id} ä¸å­˜åœ¨"

        metadata = doc_info.get("metadata", {})
        video_path = metadata.get("video_path")
        index_path = metadata.get("index_path")

        if not video_path or not index_path:
            return f"é”™è¯¯ï¼šæ–‡æ¡£ {doc_id} ç¼ºå°‘è§†é¢‘æˆ–ç´¢å¼•æ–‡ä»¶"

        # åˆå§‹åŒ– OCR å®¢æˆ·ç«¯å’Œ visual retriever
        ocr_client = DeepSeekOCRClient(endpoint=settings.ocr_api_url)
        logger.info(f"[Tool] æ­£åœ¨è°ƒç”¨ DeepSeek OCR API: {settings.ocr_api_url}")

        visual_retriever = VisualMemvidRetriever(
            video_path=video_path,
            index_path=index_path,
            ocr_client=ocr_client,
            enable_cache=True
        )

        # æ‰§è¡Œæ£€ç´¢
        if page_nums:
            # ç²¾å‡† OCRï¼šåªå¤„ç†æŒ‡å®šçš„é¡µé¢
            logger.info(f"[Tool] ç²¾å‡† OCR æ¨¡å¼ï¼šå¤„ç†æŒ‡å®šçš„ {len(page_nums)} é¡µ: {page_nums}")
            results = []
            for page_num in page_nums:
                try:
                    # æå–å¸§å¹¶ OCRï¼ˆé¡µç ä» 1 å¼€å§‹ï¼Œframe_num ä» 0 å¼€å§‹ï¼‰
                    frame_num = page_num - 1
                    frame = visual_retriever._extract_frame(frame_num)
                    if frame is not None:
                        ocr_result = ocr_client.ocr_image(frame)

                        # æ£€æŸ¥ OCR ç»“æœæ˜¯å¦ä¸º None
                        if ocr_result is None:
                            logger.warning(f"[Tool] âš ï¸ ç¬¬ {page_num} é¡µ OCR è¿”å› None")
                            continue

                        if ocr_result.get("success"):
                            content = ocr_result.get("text", "")
                            results.append({
                                "page_num": page_num,
                                "frame_num": frame_num,
                                "content": content,
                                "page_type": "OCR"
                            })
                            logger.info(f"[Tool] âœ… ç¬¬ {page_num} é¡µ OCR æˆåŠŸï¼Œå†…å®¹é•¿åº¦: {len(content)}")
                        else:
                            error_msg = ocr_result.get("error", "æœªçŸ¥é”™è¯¯")
                            logger.warning(f"[Tool] âš ï¸ ç¬¬ {page_num} é¡µ OCR å¤±è´¥: {error_msg}")
                    else:
                        logger.warning(f"[Tool] âš ï¸ ç¬¬ {page_num} é¡µå¸§æå–å¤±è´¥")
                except Exception as e:
                    logger.error(f"[Tool] âŒ ç¬¬ {page_num} é¡µå¤„ç†å‡ºé”™: {e}", exc_info=True)
        else:
            # è‡ªåŠ¨æ£€ç´¢æ¨¡å¼ï¼šä½¿ç”¨è½»é‡çº§ç´¢å¼•å®šä½é¡µé¢
            logger.info(f"[Tool] è‡ªåŠ¨æ£€ç´¢æ¨¡å¼ï¼šä½¿ç”¨ç´¢å¼•å®šä½ top-{top_k} é¡µé¢")
            results = visual_retriever.search(
                query=query,
                top_k=top_k,
                context_window=1
            )

        if results:
            logger.info(f"[Tool] DeepSeek OCR æˆåŠŸå¤„ç† {len(results)} ä¸ªé¡µé¢")

            response = f"ã€å…¨é‡ OCR ç»“æœã€‘\n"
            response += f"æ–‡æ¡£: {doc_id}\n"
            response += f"å¤„ç†äº† {len(results)} ä¸ªé¡µé¢\n"
            if page_nums:
                response += f"æ¨¡å¼: ç²¾å‡† OCRï¼ˆæŒ‡å®šé¡µç : {page_nums}ï¼‰\n\n"
            else:
                response += f"æ¨¡å¼: è‡ªåŠ¨æ£€ç´¢ï¼ˆTop-{top_k}ï¼‰\n\n"
            response += "=" * 80 + "\n\n"

            for i, page_result in enumerate(results, 1):
                page_num = page_result.get('page_num', '?')
                content = page_result.get('content', '')

                response += f"ã€é¡µé¢ {i}/{len(results)}ã€‘ç¬¬ {page_num} é¡µ\n"
                response += f"{'-' * 80}\n"
                response += f"{content}\n"
                response += f"{'-' * 80}\n\n"

            return response
        else:
            return f"åœ¨æ–‡æ¡£ {doc_id} ä¸­æœªæ‰¾åˆ°ä¸æŸ¥è¯¢ç›¸å…³çš„å†…å®¹"

    except Exception as e:
        logger.error(f"search_in_document error: {e}", exc_info=True)
        return f"æœç´¢å‡ºé”™ï¼š{str(e)}"


@tool
def evaluate_answer_confidence(query: str, answer: str) -> str:
    """
    è¯„ä¼°ç­”æ¡ˆçš„ç½®ä¿¡åº¦ã€‚
    é€‚ç”¨äºï¼šè·å¾—ç­”æ¡ˆåï¼Œåˆ¤æ–­ç­”æ¡ˆè´¨é‡æ˜¯å¦æ»¡è¶³è¦æ±‚ã€‚

    Args:
        query: åŸå§‹æŸ¥è¯¢é—®é¢˜
        answer: è·å¾—çš„ç­”æ¡ˆ

    Returns:
        ç½®ä¿¡åº¦è¯„åˆ†å’Œå»ºè®®ï¼ˆ0-1ä¹‹é—´ï¼Œ>0.9 è¡¨ç¤ºé«˜è´¨é‡ç­”æ¡ˆï¼‰
    """
    _init_globals()
    logger.info(f"[Tool] evaluate_answer_confidence")

    try:
        confidence = _llm_client.evaluate_confidence(query, answer, [])

        if confidence >= 0.9:
            return f"ç½®ä¿¡åº¦: {confidence:.2f} - ç­”æ¡ˆè´¨é‡å¾ˆé«˜ï¼Œå¯ä»¥è¿”å›ç»™ç”¨æˆ·"
        elif confidence >= 0.7:
            return f"ç½®ä¿¡åº¦: {confidence:.2f} - ç­”æ¡ˆè´¨é‡ä¸­ç­‰ï¼Œå»ºè®®ç»§ç»­æœç´¢æ›´å¤šä¿¡æ¯"
        else:
            return f"ç½®ä¿¡åº¦: {confidence:.2f} - ç­”æ¡ˆè´¨é‡è¾ƒä½ï¼Œéœ€è¦é‡æ–°æœç´¢"

    except Exception as e:
        logger.error(f"evaluate_answer_confidence error: {e}")
        return f"è¯„ä¼°å‡ºé”™ï¼š{str(e)}"


@tool
def search_in_document_summary(doc_id: str, query: str, top_k: int = 5) -> str:
    """
    åœ¨æ–‡æ¡£çš„ Summary ä¸­å¿«é€Ÿæ£€ç´¢ï¼ˆä¸è¿›è¡Œå…¨é‡ OCRï¼‰ã€‚
    é€‚ç”¨äºï¼šå¿«é€Ÿäº†è§£æ–‡æ¡£å†…å®¹ï¼Œåˆ¤æ–­æ˜¯å¦éœ€è¦æ·±å…¥ OCRã€‚

    å·¥ä½œæµç¨‹ï¼š
    1. ä½¿ç”¨è½»é‡çº§ç´¢å¼•å®šä½æœ€ç›¸å…³çš„é¡µé¢
    2. è¯»å–è¿™äº›é¡µé¢çš„ Summaryï¼ˆä» JSON æ–‡ä»¶ï¼‰
    3. è¿”å› Summary å†…å®¹ï¼Œä¸è¿›è¡Œ OCR
    4. å¦‚æœ Summary ä¸è¶³ä»¥å›ç­”é—®é¢˜ï¼Œå»ºè®®ä½¿ç”¨ search_in_document

    Args:
        doc_id: æ–‡æ¡£ ID
        query: ç”¨æˆ·æŸ¥è¯¢é—®é¢˜
        top_k: è¿”å›æœ€ç›¸å…³çš„é¡µé¢æ•°é‡ï¼ˆé»˜è®¤ 5ï¼‰

    Returns:
        ç›¸å…³é¡µé¢çš„ Summary å†…å®¹
    """
    _init_globals()
    logger.info(f"[Tool] search_in_document_summary: doc_id={doc_id}, query={query}, top_k={top_k}")

    try:
        import sys
        import json
        from pathlib import Path

        # Add project root to path
        project_root = Path(__file__).parent.parent.parent.parent
        sys.path.insert(0, str(project_root))

        from visual_memvid.bm25s_index import BM25SIndex
        from app.config import get_settings
        from app.core.library_manager import LibraryManager

        settings = get_settings()
        library_manager = LibraryManager()

        # è·å–æ–‡æ¡£ä¿¡æ¯
        doc_info = library_manager.get_document(doc_id)
        if not doc_info:
            return f"é”™è¯¯ï¼šæ–‡æ¡£ {doc_id} ä¸å­˜åœ¨"

        metadata = doc_info.get("metadata", {})
        index_path = metadata.get("index_path")
        summary_path = metadata.get("summary_path")

        if not index_path or not summary_path:
            return f"é”™è¯¯ï¼šæ–‡æ¡£ {doc_id} ç¼ºå°‘ç´¢å¼•æˆ– Summary æ–‡ä»¶"

        # åŠ è½½ BM25S ç´¢å¼•ï¼ˆä½¿ç”¨ mmap èŠ‚çœå†…å­˜ï¼‰
        index = BM25SIndex.load(index_path, mmap=True)

        # ä½¿ç”¨ç´¢å¼•å®šä½ç›¸å…³é¡µé¢ï¼ˆè¿”å›åŒ…å«åˆ†æ•°å’Œç›¸å…³æ€§ç­‰çº§çš„åˆ—è¡¨ï¼‰
        search_results = index.search(query, top_k)

        if not search_results:
            return f"åœ¨æ–‡æ¡£ {doc_id} çš„ Summary ä¸­æœªæ‰¾åˆ°ä¸æŸ¥è¯¢ç›¸å…³çš„å†…å®¹"

        logger.info(f"[Tool] å®šä½åˆ° {len(search_results)} ä¸ªç›¸å…³é¡µé¢")

        # è¯»å– Summary JSON
        with open(summary_path, 'r', encoding='utf-8') as f:
            summary_data = json.load(f)

        # å¤„ç†ä¸¤ç§å¯èƒ½çš„æ ¼å¼
        if isinstance(summary_data, list):
            # æ–°æ ¼å¼ï¼š[{"doc_id": "...", "page_num": 1, "summary": "...", ...}, ...]
            pass
        elif isinstance(summary_data, dict):
            # æ—§æ ¼å¼ï¼š{"page_summaries": ["summary1", "summary2", ...]}
            return f"é”™è¯¯ï¼šSummary æ–‡ä»¶æ ¼å¼å·²è¿‡æ—¶ï¼Œè¯·é‡æ–°ç”Ÿæˆæ–‡æ¡£"
        else:
            return f"é”™è¯¯ï¼šSummary æ–‡ä»¶æ ¼å¼ä¸æ­£ç¡®"

        # ç»Ÿè®¡ç›¸å…³æ€§ç­‰çº§
        high_relevance = [r for r in search_results if r["relevance_level"] == "é«˜"]
        mid_relevance = [r for r in search_results if r["relevance_level"] == "ä¸­"]
        low_relevance = [r for r in search_results if r["relevance_level"] == "ä½"]

        # æå–ç›¸å…³é¡µé¢çš„å®Œæ•´ Summaryï¼ˆåŒ…æ‹¬æ‰€æœ‰å­—æ®µï¼‰
        result = f"ã€Summary æ£€ç´¢ç»“æœã€‘\n"
        result += f"æ–‡æ¡£: {doc_id}\n"
        result += f"æ‰¾åˆ° {len(search_results)} ä¸ªç›¸å…³é¡µé¢\n"
        result += f"ç›¸å…³æ€§åˆ†å¸ƒ: é«˜ {len(high_relevance)} é¡µ | ä¸­ {len(mid_relevance)} é¡µ | ä½ {len(low_relevance)} é¡µ\n\n"
        result += "=" * 80 + "\n\n"

        for search_item in search_results:
            frame_num = search_item["frame_num"]
            page_num = search_item["page_num"]
            score = search_item["score"]
            score_ratio = search_item["score_ratio"]
            relevance_level = search_item["relevance_level"]
            rank = search_item["rank"]

            if frame_num < len(summary_data):
                page_data = summary_data[frame_num]
                summary_content = page_data.get("summary", "")

                result += f"ã€æ’å {rank}ã€‘ç¬¬ {page_num} é¡µ | BM25S å¾—åˆ†: {score:.2f} ({score_ratio:.0%}) | ç›¸å…³æ€§: {relevance_level}\n"
                result += f"{'-' * 80}\n"
                result += f"{summary_content}\n"
                result += f"{'-' * 80}\n\n"

        result += "=" * 80 + "\n"
        result += "ã€ä¸‹ä¸€æ­¥è¡ŒåŠ¨æŒ‡å¼• - æ¸è¿›å¼ç²¾å‡†æ£€ç´¢ã€‘\n\n"
        result += "âš ï¸ Stage 1.5: Summary æ‰¹é‡åˆ†æ\n"
        result += "   1. ä»”ç»†é˜…è¯»ä¸Šè¿°æ‰€æœ‰ Summary å†…å®¹\n"
        result += "   2. è¯„ä¼°æ¯é¡µçš„ç›¸å…³æ€§ï¼ˆå·²æ ‡æ³¨ï¼šé«˜/ä¸­/ä½ï¼‰\n"
        result += "   3. åˆ¤æ–­ Summary æ˜¯å¦è¶³å¤Ÿå›ç­”é—®é¢˜\n\n"

        result += "âš ï¸ å†³ç­–åˆ†æ”¯ï¼š\n"
        result += "   ã€åˆ†æ”¯ Aã€‘Summary è¶³å¤Ÿ â†’ ç›´æ¥åŸºäº Summary ç”Ÿæˆç­”æ¡ˆï¼Œæ ‡æ³¨'åŸºäº Summary'\n"
        result += "   ã€åˆ†æ”¯ Bã€‘Summary ä¸è¶³ â†’ è¿›å…¥ Stage 2ï¼ˆç²¾å‡† OCRï¼‰\n\n"

        result += "âš ï¸ Stage 2: ç²¾å‡† OCRï¼ˆä»…åœ¨ Summary ä¸è¶³æ—¶æ‰§è¡Œï¼‰\n"
        result += "   1. ä»ä¸Šè¿°é¡µé¢ä¸­é€‰æ‹© 3-5 é¡µæœ€ç›¸å…³çš„ï¼ˆä¼˜å…ˆé€‰æ‹©'é«˜'ç›¸å…³æ€§çš„é¡µé¢ï¼‰\n"
        result += "   2. è°ƒç”¨ search_in_documentï¼ŒæŒ‡å®š page_nums å‚æ•°\n"
        result += f"   3. ç¤ºä¾‹: search_in_document(doc_id='{doc_id}', query='{query}', page_nums=[{', '.join(str(r['page_num']) for r in high_relevance[:3])}])\n\n"

        result += "âš ï¸ ç¦æ­¢äº‹é¡¹ï¼š\n"
        result += "   âŒ ç¦æ­¢æœªå°è¯•ç”¨ Summary å›ç­”å°±ç›´æ¥è°ƒç”¨ search_in_document\n"
        result += "   âŒ ç¦æ­¢å¯¹æ‰€æœ‰ 10 é¡µéƒ½åšå…¨é‡ OCRï¼ˆæˆæœ¬é«˜ã€é€Ÿåº¦æ…¢ï¼‰\n"
        result += "   âŒ ç¦æ­¢é€‰æ‹©è¶…è¿‡ 5 é¡µè¿›è¡Œ OCR\n"

        return result

    except Exception as e:
        logger.error(f"search_in_document_summary error: {e}", exc_info=True)
        return f"æœç´¢ Summary å‡ºé”™ï¼š{str(e)}"


@tool
def get_full_document_content(doc_id: str, query: str) -> str:
    """
    è·å–å°æ–‡æ¡£çš„å®Œæ•´å†…å®¹ï¼ˆé€‚ç”¨äº <= 15 é¡µçš„æ–‡æ¡£ï¼‰ã€‚

    é€‚ç”¨åœºæ™¯ï¼š
    - åˆåŒã€ç®€å†ã€æŠ¥å‘Šç­‰è¿ç»­æ€§å¼ºçš„æ–‡æ¡£
    - éœ€è¦æ•´ä½“ç†è§£ï¼Œç‰‡æ®µæ£€ç´¢æ„ä¹‰ä¸å¤§
    - æ–‡æ¡£é¡µæ•°è¾ƒå°‘ï¼ˆ<= 15 é¡µï¼‰

    å·¥ä½œæµç¨‹ï¼š
    1. æ£€æŸ¥æ–‡æ¡£é¡µæ•°
    2. å¦‚æœ <= 15 é¡µï¼Œä¸€æ¬¡æ€§ OCR æ‰€æœ‰é¡µé¢
    3. ä½¿ç”¨ LLM åŸºäºå®Œæ•´å†…å®¹ç”Ÿæˆç­”æ¡ˆ
    4. å¦‚æœ > 15 é¡µï¼Œå»ºè®®ä½¿ç”¨ search_in_document

    Args:
        doc_id: æ–‡æ¡£ ID
        query: ç”¨æˆ·æŸ¥è¯¢é—®é¢˜

    Returns:
        åŸºäºå®Œæ•´æ–‡æ¡£å†…å®¹çš„ç­”æ¡ˆ
    """
    _init_globals()
    logger.info(f"[Tool] get_full_document_content: doc_id={doc_id}, query={query}")

    try:
        import sys
        from pathlib import Path

        # Add project root to path
        project_root = Path(__file__).parent.parent.parent.parent
        sys.path.insert(0, str(project_root))

        from visual_memvid.visual_retriever import VisualMemvidRetriever
        from visual_memvid.ocr_client import DeepSeekOCRClient
        from app.config import get_settings
        from app.core.library_manager import LibraryManager

        settings = get_settings()
        library_manager = LibraryManager()

        # è·å–æ–‡æ¡£ä¿¡æ¯
        doc_info = library_manager.get_document(doc_id)
        if not doc_info:
            return f"é”™è¯¯ï¼šæ–‡æ¡£ {doc_id} ä¸å­˜åœ¨"

        metadata = doc_info.get("metadata", {})
        total_pages = metadata.get("page_count", 0)

        # æ£€æŸ¥é¡µæ•°é™åˆ¶
        if total_pages > 15:
            return (
                f"æ–‡æ¡£ {doc_id} å…± {total_pages} é¡µï¼Œè¶…è¿‡ 15 é¡µé™åˆ¶ã€‚\n"
                f"å»ºè®®ä½¿ç”¨ search_in_document å·¥å…·è¿›è¡Œç‰‡æ®µæ£€ç´¢ã€‚"
            )

        logger.info(f"[Tool] æ–‡æ¡£å…± {total_pages} é¡µï¼Œå¼€å§‹å…¨é‡ OCR...")

        video_path = metadata.get("video_path")
        index_path = metadata.get("index_path")

        if not video_path or not index_path:
            return f"é”™è¯¯ï¼šæ–‡æ¡£ {doc_id} ç¼ºå°‘è§†é¢‘æˆ–ç´¢å¼•æ–‡ä»¶"

        # åˆå§‹åŒ– OCR å®¢æˆ·ç«¯
        ocr_client = DeepSeekOCRClient(endpoint=settings.ocr_api_url)

        visual_retriever = VisualMemvidRetriever(
            video_path=video_path,
            index_path=index_path,
            ocr_client=ocr_client,
            enable_cache=True
        )

        # ä¸€æ¬¡æ€§ OCR æ‰€æœ‰é¡µé¢ï¼ˆä½¿ç”¨æ‰¹é‡ OCRï¼‰
        all_pages_content = []
        for page_num in range(total_pages):
            # æå–å¸§å¹¶ OCR
            frame = visual_retriever._extract_frame(page_num)
            if frame is not None:
                ocr_result = ocr_client.ocr_image(frame)
                if ocr_result.get("success"):
                    content = ocr_result.get("content", "")
                    all_pages_content.append(f"=== ç¬¬ {page_num + 1} é¡µ ===\n{content}")

        if not all_pages_content:
            return f"é”™è¯¯ï¼šæ— æ³•æå–æ–‡æ¡£ {doc_id} çš„å†…å®¹"

        # åˆå¹¶æ‰€æœ‰é¡µé¢å†…å®¹
        full_content = "\n\n".join(all_pages_content)

        logger.info(f"[Tool] å…¨é‡ OCR å®Œæˆï¼Œå…± {len(all_pages_content)} é¡µ")

        # ä½¿ç”¨ LLM åŸºäºå®Œæ•´å†…å®¹ç”Ÿæˆç­”æ¡ˆ
        answer_prompt = f"""åŸºäºä»¥ä¸‹æ–‡æ¡£çš„å®Œæ•´å†…å®¹ï¼Œå›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚

ç”¨æˆ·é—®é¢˜ï¼š{query}

æ–‡æ¡£å®Œæ•´å†…å®¹ï¼š
{full_content[:8000]}  # é™åˆ¶é•¿åº¦é¿å…è¶…å‡º token é™åˆ¶

è¯·æä¾›å‡†ç¡®ã€è¯¦ç»†çš„ç­”æ¡ˆã€‚"""

        answer_result = _llm_client.chat(
            messages=[{"role": "user", "content": answer_prompt}],
            temperature=0.3
        )

        if answer_result.get("success"):
            answer = answer_result.get("content", "")
            return f"åŸºäºæ–‡æ¡£ {doc_id} çš„å®Œæ•´å†…å®¹ï¼ˆå…± {total_pages} é¡µï¼‰ï¼š\n\n{answer}"
        else:
            return f"é”™è¯¯ï¼šç”Ÿæˆç­”æ¡ˆå¤±è´¥ - {answer_result.get('error')}"

    except Exception as e:
        logger.error(f"get_full_document_content error: {e}", exc_info=True)
        return f"è·å–æ–‡æ¡£å†…å®¹å‡ºé”™ï¼š{str(e)}"


class DKRAgent:
    """
    DKR Agent - åŸºäº LangGraph çš„è‡ªä¸»æ–‡æ¡£æ£€ç´¢ Agent

    ç‰¹æ€§ï¼š
    - è‡ªä¸»å†³ç­–å·¥å…·è°ƒç”¨é¡ºåº
    - å¾ªç¯è°ƒç”¨ç›´åˆ°æ‰¾åˆ°æ»¡æ„ç­”æ¡ˆ
    - æ”¯æŒçŠ¶æ€æŒä¹…åŒ–
    - ç±»ä¼¼ Claude Agentic Search çš„å·¥ä½œæ–¹å¼
    """

    def __init__(self):
        self.settings = get_settings()
        self.confidence_threshold = self.settings.agent_confidence_threshold

        # åˆå§‹åŒ–å…¨å±€å®ä¾‹
        _init_globals()

        # åˆ›å»º LangChain LLMï¼ˆæ ¹æ®é…ç½®é€‰æ‹© DeepSeek æˆ– Geminiï¼‰
        if self.settings.agent_llm_provider == "gemini":
            logger.info(f"ä½¿ç”¨ Gemini æ¨¡å‹: {self.settings.agent_llm_model}")
            self.llm = ChatOpenAI(
                base_url=self.settings.openrouter_base_url,
                api_key=self.settings.openrouter_api_key,
                model=self.settings.agent_llm_model,
                temperature=0.3
            )
        else:
            logger.info(f"ä½¿ç”¨ DeepSeek æ¨¡å‹: {self.settings.deepseek_model}")
            self.llm = ChatOpenAI(
                base_url=self.settings.deepseek_base_url,
                api_key=self.settings.deepseek_api_key,
                model=self.settings.deepseek_model,
                temperature=0.3
            )

        # å®šä¹‰å·¥å…·åˆ—è¡¨
        self.tools = [
            search_library_overview,
            search_in_category,
            search_in_document_summary,
            search_in_document,
            get_full_document_content,
            evaluate_answer_confidence
        ]

        # åˆ›å»º Agentï¼ˆå¸¦çŠ¶æ€æŒä¹…åŒ–ï¼‰
        self.memory = MemorySaver()
        self.agent = create_react_agent(
            self.llm,
            self.tools,
            state_modifier=self._get_system_prompt(),
            checkpointer=self.memory
        )

        logger.info("DKRAgent initialized with LangGraph")

    def _get_system_prompt(self) -> str:
        """è·å– Agent ç³»ç»Ÿæç¤ºè¯ï¼ˆä»æ–‡ä»¶è¯»å–ï¼‰"""
        from pathlib import Path

        # è¯»å– Prompt æ–‡ä»¶ï¼ˆbackend/prompts/agent_system_prompt.txtï¼‰
        # dkr_agent.py åœ¨ backend/app/agent/ï¼Œæ‰€ä»¥éœ€è¦ parent.parent.parent
        prompt_file = Path(__file__).parent.parent.parent / "prompts" / "agent_system_prompt.txt"

        try:
            with open(prompt_file, 'r', encoding='utf-8') as f:
                prompt_template = f.read()

            # æ›¿æ¢å ä½ç¬¦
            prompt = prompt_template.format(
                confidence_threshold=self.confidence_threshold
            )

            return prompt
        except Exception as e:
            logger.error(f"è¯»å– Agent Prompt æ–‡ä»¶å¤±è´¥: {e}")
            # é™çº§åˆ°é»˜è®¤ Prompt
            return f"""ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½æ–‡æ¡£æ£€ç´¢åŠ©æ‰‹ã€‚ç½®ä¿¡åº¦é˜ˆå€¼ï¼š{self.confidence_threshold}"""
    
    async def ask(
        self,
        query: str,
        thread_id: str = "default"
    ) -> Dict[str, Any]:
        """
        å¤„ç†ç”¨æˆ·æŸ¥è¯¢ï¼ˆLangGraph Agent è‡ªä¸»å¾ªç¯ï¼‰

        Args:
            query: ç”¨æˆ·æŸ¥è¯¢
            thread_id: ä¼šè¯çº¿ç¨‹ IDï¼ˆç”¨äºçŠ¶æ€æŒä¹…åŒ–ï¼‰

        Returns:
            æŸ¥è¯¢ç»“æœ
        """
        start_time = datetime.now()
        logger.info(f"Agent å¼€å§‹å¤„ç†æŸ¥è¯¢: {query}")

        try:
            # é…ç½®ä¼šè¯çŠ¶æ€å’Œé€’å½’é™åˆ¶
            config = {
                "configurable": {"thread_id": thread_id},
                "recursion_limit": 50  # å¢åŠ é€’å½’é™åˆ¶åˆ° 50ï¼ˆé»˜è®¤ 25ï¼‰
            }

            # è°ƒç”¨ LangGraph Agentï¼ˆè‡ªä¸»å¾ªç¯è°ƒç”¨å·¥å…·ï¼‰
            logger.info("=" * 80)
            logger.info(f"ã€Agent å¼€å§‹æ‰§è¡Œã€‘")
            logger.info(f"æŸ¥è¯¢: {query}")
            logger.info(f"Thread ID: {thread_id}")
            logger.info("=" * 80)

            result = await self.agent.ainvoke(
                {"messages": [HumanMessage(content=query)]},
                config=config
            )

            # æå–æœ€ç»ˆç­”æ¡ˆ
            messages = result.get("messages", [])
            if not messages:
                return self._create_response(
                    success=False,
                    error="Agent æœªè¿”å›ä»»ä½•æ¶ˆæ¯",
                    processing_time=(datetime.now() - start_time).total_seconds()
                )

            # æ—¥å¿—ï¼šè®°å½• Agent çš„å®Œæ•´æ‰§è¡Œè¿‡ç¨‹
            logger.info("\n" + "=" * 80)
            logger.info(f"ã€Agent æ‰§è¡Œè¿‡ç¨‹ã€‘å…± {len(messages)} æ¡æ¶ˆæ¯")
            logger.info("=" * 80)

            for i, msg in enumerate(messages, 1):
                msg_type = getattr(msg, 'type', 'unknown')

                if msg_type == 'human':
                    logger.info(f"\n[{i}] ğŸ‘¤ ç”¨æˆ·æ¶ˆæ¯:")
                    logger.info(f"    {msg.content[:200]}")

                elif msg_type == 'ai':
                    logger.info(f"\n[{i}] ğŸ¤– Agent æ€è€ƒ:")
                    # æ£€æŸ¥æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨
                    if hasattr(msg, 'tool_calls') and msg.tool_calls:
                        for tool_call in msg.tool_calls:
                            tool_name = tool_call.get('name', 'unknown')
                            tool_args = tool_call.get('args', {})
                            logger.info(f"    ğŸ“ è°ƒç”¨å·¥å…·: {tool_name}")
                            logger.info(f"    ğŸ“ å‚æ•°: {tool_args}")
                    else:
                        # Agent çš„æœ€ç»ˆå›ç­”
                        content = msg.content[:500] if hasattr(msg, 'content') else str(msg)[:500]
                        logger.info(f"    ğŸ’¬ å›ç­”: {content}")

                elif msg_type == 'tool':
                    logger.info(f"\n[{i}] ğŸ”§ å·¥å…·è¿”å›:")
                    tool_name = getattr(msg, 'name', 'unknown')
                    content = msg.content[:300] if hasattr(msg, 'content') else str(msg)[:300]
                    logger.info(f"    å·¥å…·: {tool_name}")
                    logger.info(f"    ç»“æœ: {content}...")

                else:
                    logger.info(f"\n[{i}] â“ æœªçŸ¥æ¶ˆæ¯ç±»å‹: {msg_type}")

            # æœ€åä¸€æ¡æ¶ˆæ¯æ˜¯ Agent çš„æœ€ç»ˆå›å¤
            final_message = messages[-1]
            answer = final_message.content if hasattr(final_message, 'content') else str(final_message)

            processing_time = (datetime.now() - start_time).total_seconds()

            logger.info("\n" + "=" * 80)
            logger.info(f"ã€Agent å®Œæˆã€‘")
            logger.info(f"æ‰§è¡Œæ­¥éª¤: {len(messages)} æ¡æ¶ˆæ¯")
            logger.info(f"è€—æ—¶: {processing_time:.2f}s")
            logger.info(f"æœ€ç»ˆç­”æ¡ˆé•¿åº¦: {len(answer)} å­—ç¬¦")
            logger.info("=" * 80)
            logger.info("\nğŸ“ ã€æœ€ç»ˆç­”æ¡ˆã€‘")
            logger.info("=" * 80)
            logger.info(answer)
            logger.info("=" * 80)

            return self._create_response(
                success=True,
                answer=answer,
                processing_time=processing_time
            )

        except Exception as e:
            logger.error(f"Agent å¤„ç†å¤±è´¥: {e}", exc_info=True)
            processing_time = (datetime.now() - start_time).total_seconds()
            return self._create_response(
                success=False,
                error=str(e),
                processing_time=processing_time
            )
    
    def _create_response(
        self,
        success: bool,
        answer: Optional[str] = None,
        processing_time: float = 0.0,
        error: Optional[str] = None
    ) -> Dict[str, Any]:
        """åˆ›å»ºå“åº”ï¼ˆåªè¿”å›æœ€ç»ˆç­”æ¡ˆï¼Œä¸è¿”å›æ‰§è¡Œæ­¥éª¤ï¼‰"""
        return {
            "success": success,
            "answer": answer,
            "processing_time": processing_time,
            "error": error
        }

